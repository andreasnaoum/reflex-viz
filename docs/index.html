<!doctype html>
<html lang="en">


<!-- === Header Starts === -->
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>JOSH</title>

  <link href="./assets/bootstrap.min.css" rel="stylesheet">
  <link href="./assets/font.css" rel="stylesheet" type="text/css">
  <link href="./assets/style.css" rel="stylesheet" type="text/css">
</head>
<!-- === Header Ends === -->


<body>

<!-- === Home Section Starts === -->
<div class="section">
  <!-- === Title Starts === -->
  <div class="header">
    <div class="title" style="padding-top: 25pt;">  <!-- Set padding as 10 if title is with two lines. -->
      REFLEX Dataset: A Multimodal Dataset of Human Reactions to Robot Failures and Explanations
    </div>
  </div>
  <!-- === Title Ends === -->
  <div class="author">
    <a href="https://www.kth.se" target="_blank">Parag Khanna</a>&nbsp;,
    <a href="https://www.kth.se" target="_blank">Andreas Naoum</a>&nbsp;,
    <a href="https://www.kth.se" target="_blank">Elmira Yadollahi</a>&nbsp;,
    <a href="https://www.kth.se" target="_blank">Mårten Björkman</a>
    <a href="https://www.kth.se" target="_blank">Christian Smith</a>
  </div>
  <div class="institution">
    KTH Royal Institute of Technology
  </div>
  <div class="link">
    <a href="https://zenodo.org/records/14160783" target="_blank">[Dataset]</a>&nbsp;
    <a href="https://arxiv.org/abs/2502.14185" target="_blank">[Paper]</a>&nbsp;
    <a href="https://github.com/andreasnaoum/reflex-viz" target="_blank">[Code]</a>
  </div>

   <div style="position: relative; padding-top: 50.25%; margin: 0pt 0; text-align: center;">
    <video muted autoplay playsinline controls loop style="position: absolute; top: 0%; left: 0%; width: 100%; height: 100%;">
        <source src="assets/demo.mov" type="video/mp4">
        Your browser does not support the video tag.
    </video>
</div>
  <!-- <div class="teaser">
    <img src="assets/teaser.jpg">
  </div>
  <div class="teaser">
    <img src="assets/demo.png">
  </div> -->
</div>
<!-- === Home Section Ends === -->
<!-- <div class="section">
  <div class="title">Interactive Demos on Web Videos</div>
<div id="demo1">
<script type="module" src="./src/demo1.js"></script>
</div>
<div id="demo2">
  <script type="module" src="./src/demo2.js"></script>
  </div>
  <div id="demo3">
    <script type="module" src="./src/demo3.js"></script>
    </div>
</div> -->
</div>

<!-- === Overview Section Starts === -->
<div class="section">
  <div class="title">Overview</div>
  <div class="body">

  REFLEX (Robotic Explanations to FaiLures and Human EXpressions) is a comprehensive multimodal dataset capturing human reactions to robot failures and subsequent explanations in collaborative settings. This dataset facilitates research into human-robot interaction dynamics, addressing the need to study reactions to both initial failures and explanations, as well as the evolution of these reactions in long-term interactions.
  </div>

</div>

<!-- === Result Section Ends === -->
<div class="section">
  <div class="title">Interactive Demo on Web Video</div>
  Sample of visualization.
<div id="demo1">
<script type="module" src="./src/demo1.js"></script>
</div>
</div>

<!-- === Reference Section Starts === -->
<div class="section">
  <div class="bibtex">BibTeX</div>
<pre>
@article{reflex_dataset,
    title={REFLEX Dataset: A Multimodal Dataset of Human Reactions to Robot Failures and Explanations},
    author={Parag Khanna and Andreas Naoum and Elmira Yadollahi and Mårten Björkman and Christian Smith},
    year={2025},
    eprint={2502.14185},
    archivePrefix={arXiv},
    primaryClass={cs.RO},
    url={https://arxiv.org/abs/2502.14185},
}
</pre>

</div>

</body>
</html>
